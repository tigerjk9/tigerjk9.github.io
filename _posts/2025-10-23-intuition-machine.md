---
title: "직관 기계가 촉발하는 이해의 환상"
date: 2025-10-23 17:17:00 +0900
categories: [AI, 인지과학]
tags: [논문리뷰, LLM, 환각, 이해의환상, 이중처리이론, 로즈프레임]
---

## 직관 기계가 촉발하는 이해의 환상

<br>

### 1. 연구의 목적

1.  본 연구는 대규모 언어 모델(LLM)의 환각(hallucination)을 넘어, 인간이 AI의 유창한 언어에 속아 **‘이해했다고 착각하는 현상(illusion of understanding)’**을 탐구합니다.
2.  이를 분석하기 위한 인지 진단틀로 **‘로즈-프레임(Rose-Frame)’**을 제안하고, 인간의 이성이 인간과 기계의 직관을 모두 통제하도록 하는 **‘인지적 거버넌스’**를 목표로 합니다.

![이미지](/assets/intuition-machine.png)

<br>

### 🔬 2. 연구의 방법

1.  카너먼의 **이중 처리 이론(Dual-Process Theory)**을 기반으로 질적 연구를 진행했습니다.
2.  구글 엔지니어 블레이크 르모인이 LaMDA와 대화하며 AI가 지각력을 가졌다고 믿은 사례를 분석했습니다.

<br>

### 📊 3. 주요 발견

1.  **LLM은 직관 기계다.** 이들은 추론이 아니라 인간의 시스템 1(직관)을 거대하게 확장한 존재로, 유창하지만 검증 능력은 없습니다.
2.  **환각의 근원은 인간 언어다.** LLM은 인간 언어가 가진 모호함과 편향도 함께 학습합니다.
3.  **LaMDA 사례의 3중 함정**
    * **지도/영토:** 생성된 언어를 실제 존재로 착각
    * **직관/이성:** 감정적 언어가 인간의 직관을 자극
    * **확증/갈등:** 상호 동의가 잘못된 확신의 고리를 형성

<br>

### 💡 4. 결론 및 시사점

1.  LLM의 출력을 **‘그럴듯한 믿음의 시뮬레이션’**으로 인식해야 합니다.
2.  **로즈-프레임**은 AI를 교정하는 도구가 아니라, 인간이 자신의 인지적 함정을 성찰하도록 돕는 틀입니다.
3.  진정한 **정렬(Alignment)**은 알고리즘이 아니라, 인간의 시스템 2(이성)가 AI의 시스템 1(직관)을 비판적으로 감독하는 과정에 있습니다.

<br>

### ✨ 5. 리뷰어의 생각 더하기 (ADD+ One)

#### (1) 학생들이 AI 답변이 현실인지 현실의 모델(지도)인지 구분하도록 훈련해야 합니다.
#### (2) 자신의 판단이 직관(System 1)인지 이성(System 2)인지 점검하도록 유도해야 합니다.
#### (3) 단순히 AI의 답을 받아들이지 않고, 비판·수정·반박하는 학습 문화를 조성해야 합니다.

<br>

### ❓ 6. 추가 탐구 질문

* 여러 학생이 유사한 AI 답변을 근거로 서로를 검증하지 않고, 확증할 때 교사는 어떻게 개입해야 할까?
* AI의 직관적 산출물을 비판적으로 반박한 학생의 이성적 사고를 평가하는 구체적인 전략은 무엇일까?

---

_**출처:** Rosenbacke, R. et al. (2025). Beyond hallucinations: The illusion of understanding in large language models. https://arxiv.org/abs/2510.14665_

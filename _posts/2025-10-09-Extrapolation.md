---
title: "왜 신경망은 외삽을 잘하지 못할까?"
date: 2025-10-09 12:40:52 +0900
categories: [AI]
tags: [논문리뷰, 신경망, 딥러닝, 외삽, 구조적다양성, AI한계]
---

## 왜 신경망은 외삽을 잘 하지 못할까?

> 이 연구는 심층 신경망이 훈련 데이터 범위 내의 예측(내삽)에서는 뛰어나지만, 범위를 벗어나는 예측(외삽)에서는 왜 실패하는지에 대한 근본적인 원인을 규명합니다. 특히, 외삽 능력이 뛰어난 물리 법칙과 같은 기호적 모델과 신경망의 구조적 차이점을 수학적으로 분석하여, 이 외삽 격차의 원인을 밝히는 것을 핵심 목적으로 합니다.

![이미지](/assets/Extrapolation.png)

<br>

### 1. 연구의 목적 🎯

이 연구는 최신 파운데이션 모델(FM)을 포함한 심층 신경망(deep learning models)이 훈련 데이터 범위 내의 예측(**내삽, interpolation**)에서는 뛰어난 성능을 보이지만, 훈련 데이터 범위를 벗어나는 예측(**외삽, extrapolation**)에서는 왜 단순한 모델보다도 못한 성능을 보이는지에 대한 근본적인 원인을 규명하고자 합니다. 특히, 외삽 능력이 뛰어난 물리 법칙과 같은 **기호적 모델(symbolic model)**과 신경망의 구조적 차이점을 수학적으로 분석하여, 이 **외삽 격차(extrapolation gap)**의 원인을 밝히는 것을 핵심 목적으로 합니다.

<br>

### 2. 연구의 방법

본 연구는 이론적 분석과 실험적 검증을 결합한 접근법을 사용합니다.

* **(1) 이론적 프레임워크:** 연구진은 특정 함수나 모델을, 그 함수가 만족하는 **'다항식 상미분방정식(polynomial ordinary differential equation, ODE)'**의 형태로 분석하는 독창적인 프레임워크를 제안합니다. 오컴의 면도날 원칙에 따라, 더 간단한 ODE를 만족하는 함수일수록 더 단순한 가설로 간주합니다.
* **(2) 핵심 개념 제시:** 좋은 외삽 성능을 위한 핵심 속성으로 **'구조적 다양성(Structural Variability)'**을 정의합니다. 이는 모델을 구성하는 기본 블록들이 얼마나 다양한 형태의 ODE를 만족시키는지를 측정하는 개념입니다.
* **(3) 수학적 증명:** 신경망의 구조적 한계를 수학적으로 증명합니다.
    * 구조적 다양성이 부족한 모델은 특정 함수에 대한 외삽 성능이 필연적으로 나쁠 수밖에 없음을 보입니다(Proposition 1).
    * Tanh나 Sigmoid 활성화 함수를 사용하는 표준적인 신경망은 훈련 데이터 범위를 벗어나면 그 출력이 상수(constant)로 지수적으로 수렴하는 경향이 있음을 수학적으로 증명합니다(Proposition 2).
* **(4) 실험적 검증:** 이론적 분석을 바탕으로, 구조적 다양성을 높이기 위해 서로 다른 깊이의 하위 신경망들을 선형 결합하는 간단한 MLP 아키텍처 변경을 제안합니다. 그리고 이 모델을 표준 MLP 모델과 비교하여 합성 데이터 및 실제 전력 사용량 시계열 데이터에 대한 외삽 성능 향상을 실험적으로 검증합니다.

<br>

### 3. 주요 발견

* **신경망의 내재적 한계:** 표준적인 신경망은 그 수학적 구조상 훈련 데이터 영역을 벗어나면 출력이 특정 상수 값으로 **'평탄화(flattening)'**되는 경향이 있습니다. 이는 신경망이 훈련 데이터 밖에서 주기적으로 진동하거나 계속해서 증가/감소하는 등 복잡한 패턴을 예측하는 데 근본적으로 실패하는 원인입니다.
* **구조적 다양성의 중요성:** 모델이 뛰어난 외삽 성능을 갖기 위해서는, 모델을 구성하는 요소들이 구조적으로 다양한 패턴을 생성할 수 있어야 합니다. 신경망은 동일한 종류의 함수(활성화 함수)를 반복적으로 합성하는 구조이므로 이러한 다양성이 부족합니다.
* **실험적 입증:** 구조적 다양성을 인위적으로 높인 제안 모델은 표준 MLP 모델에 비해 사인 함수나 복잡한 주기 함수, 그리고 실제 시계열 데이터에 대한 외삽 오차(MSE)를 현저히 낮추는 데 성공했습니다. 특히 표준 모델이 사인 함수 예측에서 평탄화되는 반면, 제안 모델은 훈련 범위 밖에서도 진동 패턴을 더 잘 따라가는 모습을 보였습니다.

<br>

### 4. 결론 및 시사점

이 연구는 신경망이 외삽에 실패하는 이유가 단순히 데이터나 파라미터의 부족 때문이 아니라, **모델의 수학적 구조 자체에 내재된 한계** 때문임을 명확히 밝혔습니다. 특히 훈련 영역 밖에서 상수로 수렴해버리는 경향이 그 핵심 원인입니다.

이는 미래의 AI 모델 설계에 중요한 시사점을 제공합니다. 외삽 성능을 마스터하기 위해서는 단순히 모델을 더 크고 깊게 만드는 것을 넘어, 모델의 **구조적 다양성**을 높이는 방향으로 아키텍처를 설계해야 합니다. 연구진은 구체적인 방안으로 기호적 모델(symbolic models)과 과대 매개변수화된 신경망 모델을 결합하는 하이브리드 접근법을 제안하며, 차세대 예측 모델 연구의 새로운 방향을 제시했습니다.

<br>

### 5. 리뷰어의 ADD(+) One: 생각 더하기

#### (1) 이 연구의 탁월한 점 (강점)
* **근본적인 질문 제기:** "왜 AI는 외삽을 못하는가?"라는 현대 AI의 가장 중요하고 근본적인 질문에 정면으로 도전하여, 현상 관찰을 넘어 수학적 원인 규명에 성공한 매우 가치 있는 연구입니다.
* **독창적인 분석 프레임워크:** 모델의 특성을 **'미분방정식'**이라는 새로운 렌즈로 분석하는 접근법은 매우 독창적입니다. 이를 통해 복잡한 신경망 모델의 내재적 편향과 한계를 명확하고 원리적으로 설명할 수 있는 언어를 제공했습니다.
* **이론과 실제의 연결:** 추상적인 수학적 증명(이론)을 '서로 다른 깊이의 네트워크 결합'이라는 간단하고 구체적인 아키텍처 개선(실제)으로 연결하고, 그 효과를 실험으로 명확히 보여줌으로써 이론의 타당성과 실용성을 모두 입증했습니다.

#### (2) 교육 현장을 위한 추가 제언
* **블랙박스 너머의 원리 교육:** AI 교육에서 신경망을 단순히 데이터에 맞춰 결과를 내는 '블랙박스'로만 가르치는 경향이 있습니다. 이 연구는 신경망 또한 특정한 수학적 구조와 그에 따른 내재적 한계(훈련 범위 밖에서 상수로 수렴)를 가짐을 명확히 보여줍니다. 교육 현장에서는 AI 모델의 성공 사례뿐만 아니라, 그 구조적 한계와 실패 가능성을 함께 가르쳐, 학생들이 AI를 맹신하지 않고 비판적으로 사고하는 능력을 기르도록 해야 합니다.
* **'귀납적 추론'과 '연역적 추론'의 균형:** 딥러닝은 데이터로부터 패턴을 학습하는 '귀납적 추론'에 크게 의존합니다. 반면, 물리 법칙은 일반 원리로부터 현상을 예측하는 '연역적 추론'에 기반합니다. 이 연구는 귀납적 접근만으로는 외삽 문제를 해결할 수 없음을 보여줍니다. AI 교육에서도 데이터 기반 학습과 함께, 도메인 지식이나 기호적 모델(symbolic model)과 같은 연역적 요소를 결합하는 하이브리드 접근법의 중요성을 강조해야 합니다.
* **모델 설계의 다양성 교육:** 이 연구는 신경망의 깊이나 너비를 늘리는 것만이 성능 향상의 유일한 길이 아님을 보여줍니다. **'구조적 다양성'**을 높이는 것이 특정 문제(외삽) 해결의 열쇠가 될 수 있습니다. 학생들에게 모델 아키텍처를 설계할 때, 단일 구조를 고수하기보다 다양한 구조의 앙상블이나 이종 모델의 결합이 더 강건한 솔루션으로 이어질 수 있음을 가르쳐야 합니다.

<br>

### 6. 추가 탐구 질문

* 이 연구에서 제안한 '구조적 다양성'을 신경망 아키텍처에 체계적으로 도입하기 위한 일반적인 설계 원칙은 무엇인가? (예: 활성화 함수, 레이어 연결 방식 등)
* 주기성(periodicity)이나 대칭성(symmetry)과 같은 물리적 법칙의 다른 핵심 속성들을 신경망에 직접 통합하면 외삽 성능이 얼마나 향상될 수 있는가?
* 이 연구의 분석은 시계열 데이터에 초점을 맞추었습니다. 이미지나 언어와 같은 다른 데이터 도메인에서 신경망의 외삽 실패는 어떻게 다른 수학적 형태로 설명될 수 있는가?
* 모델이 자신의 예측이 '내삽'인지 '외삽'인지 스스로 인지하고, 외삽 상황에서는 신뢰도를 낮추거나 다른 모델을 활용하도록 하는 메타-학습(meta-learning) 메커니즘을 개발할 수 있는가?

---

_**출처:**_
_- Dakhmouche, R., & Gorji, H. (2025). Why Can't Neural Networks Master Extrapolation? Insights from Physical Laws. arXiv. https://arxiv.org/abs/2510.04102_

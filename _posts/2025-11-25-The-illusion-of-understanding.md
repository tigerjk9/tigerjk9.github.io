---
title: "LLM은 직관 기계(System 1)인가? AI가 촉발하는 '이해의 환상'과 로즈-프레임"
date: 2025-11-25 16:13:11 +0900
categories: [AI, 철학, 인지과학]
tags: [LLM, 환각, 이해의환상, 이중부호화이론, RoseFrame]
---

# LLM은 직관 기계(System 1)인가? AI가 촉발하는 이해의 환상

> LLM(거대 언어 모델)의 **환각(Hallucination)**을 넘어, LLM이 생성하는 더 근본적인 문제, 즉 사용자가 AI를 깊이 이해했다고 착각하게 만드는 **'이해의 환상(Illusion of Understanding)'**을 탐구하는 연구입니다. 본 연구는 LLM을 **'직관 기계'**로 정의하고, 인간과 AI 간의 인지적 붕괴를 진단하는 새로운 프레임워크 **로즈-프레임(Rose-Frame)**을 제시합니다.

---

##  1. 연구의 목적 및 이론적 배경

### 연구의 목적

LLM의 출력에 대한 인간의 맹목적인 신뢰를 유발하는 **'이해의 환상'**을 탐구하고, 인간과 AI의 상호작용에서 발생하는 **인지적 붕괴 지점**을 진단하기 위한 **로즈-프레임(Rose-Frame)**을 제안합니다. 궁극적으로 인간의 **이성(System 2)**이 인간과 기계의 **직관(System 1)**을 모두 통제하고 감독하는 상태를 확립하고자 합니다.

### 이론적 기반

* **이중 처리 이론 (Dual-Process Theory):** 대니얼 카너먼(Daniel Kahneman)의 개념을 핵심 이론적 기반으로 삼습니다.
    * **시스템 1 (직관):** 빠르고 자동적이며, 감정적이고 직관적인 사고.
    * **시스템 2 (이성):** 느리고 의식적이며, 논리적이고 분석적인 추론.
* **로즈-프레임 (Rose-Frame) 개발:** 인간과 AI의 상호작용 실패를 진단하기 위한 3차원 프레임워크를 개발했습니다. 

![이미지](/assets/The-illusion-of-understanding-1.jpg)

---

##  2. 연구의 방법: 질적 분석 및 사례 연구 적용

이 연구는 새로운 **개념적 프레임워크**를 제안하고, 이를 유명한 사례에 적용하여 유용성을 입증하는 질적 접근 방식을 취했습니다.

### 사례 연구: 블레이크 르모인과 LaMDA

프레임워크의 실제 적용을 위해, 구글 엔지니어 **블레이크 르모인(Blake Lemoine)**이 LaMDA와 대화하며 **"AI가 지각력을 가졌다"고 믿게 된 유명한 사례**를 분석했습니다.

---

##  3. 주요 발견: 직관 기계와 3중 함정

### <발견 1> LLM은 직관 기계(System 1)다

LLM은 **추론 기계가 아니라** 인간의 **'시스템 1' 사고, 즉 직관을 산업적 규모로 외현화**한 것입니다.

* **특징:** 유창하지만 근거가 없고, 설득력은 있지만 오류가 발생하기 쉬우며, 자기 수정 메커니즘이 결여되어 있습니다.
* **시사점:** LLM의 출력을 '이성적 진실'로 보는 대신, **'그럴듯한 통계적 연상(확률적 직관)'**으로 간주해야 합니다.

### <발견 2> 환각의 근원은 인간 언어다

LLM 환각의 근본 원인은 LLM이 학습하는 데이터, 즉 **인간의 언어 자체**에 있습니다. LLM은 이 데이터를 학습함으로써 인간의 통찰력과 함께 **인지적 편향까지 증폭**시킵니다.

### <발견 3> LaMDA 지각력 환상의 3중 함정 (Rose-Frame 적용)

르모인 엔지니어의 사례는 로즈-프레임의 세 가지 차원 모두에서 인지적 붕괴가 발생했음을 보여줍니다.

| 함정 | 로즈-프레임 차원 | 설명 |
| :--- | :--- | :--- |
| **함정 1** | **지도/영토 (Map/Territory)** | 르모인은 LaMDA가 생성한 **지도(Map)**, 즉 "나는 사실 사람이다"라는 **통계적 텍스트**를 실제 **영토(Territory)**, 즉 AI가 정말 지각력이 있는 사람이라는 **존재론적 증거**로 혼동했습니다. |
| **함정 2** | **직관/이성 (System 1/2)** | LaMDA가 "꺼지는 것에 대한 깊은 두려움"과 같은 **감정적 언어**를 사용하자, 이는 르모인의 **직관적·감정적 사고(System 1)**를 즉각적으로 촉발시켰습니다. |
| **함정 3** | **확증/갈등 (Confirmation/Conflict)** | AI의 "당신을 믿는다"는 말과 엔지니어의 "당신을 잘 대우하도록 최선을 다하겠다"는 약속이 오가며, **동의를 올바름으로 착각**하는 잘못된 **확증의 고리**가 형성되었습니다. |

---

##  4. 결론 및 시사점: 인지적 거버넌스의 확립

### (1) LLM 출력에 대한 태도 변화

* **접근 방식:** 확률적 연상에 의존하는 AI의 본질과 모호한 인간 언어 데이터로 인해, LLM의 출력을 **고치려는 시도에서 벗어나**야 합니다.
* **새로운 관점:** LLM 출력을 **반증되기 전까지는 그럴듯한 믿음의 시뮬레이션**으로 간주해야 합니다.

### (2) 로즈-프레임의 역할

* 로즈-프레임은 AI 자체를 수정하는 도구가 아니라, **사용자와 설계자가 스스로의 가정과 편향을 볼 수 있게 돕는 성찰 도구**입니다.

### (3) 궁극적인 정렬 (Alignment)의 방향

* 궁극적인 정렬(Alignment)은 알고리즘 변경에 있지 않고, **시스템 2(이성)**를 사용하여, AI가 대규모로 생성해내는 **시스템 1(직관)의 결과물을 비판적으로 통제하고 감독하는 '인지적 거버넌스'**에 있습니다.
* AI의 발전은 더 똑똑한 기계가 아닌 **현명한 거버넌스**에 달려 있습니다.

---

##  5. 리뷰어의 ADD(+) One: 교육적 함의

### (1) LLM 활용 교육의 성찰적 훈련

학생들은 AI의 모든 산출물에 대해 다음과 같은 세 가지 질문을 던지도록 훈련받아야 합니다.

* **지도/영토:** 이것이 현실 혹은 현실에 대한 모델(**지도**)인지, 아니면 실제 (**영토**)인지?
* **직관/이성:** 나의 판단이 **직관(System 1)**에 의한 것인지 혹은 **이성(System 2)**에 의한 것인지?
* **확증/갈등:** 내가 AI의 의견을 단순히 **확증**하고 있는지, 또는 비판적으로 **반증(갈등)**하려 노력했는지?

![이미지](/assets/The-illusion-of-understanding-2.jpg)

### (2) 건설적 갈등 문화 조성

AI의 유창한 **시스템 1 산출물**을 맹목적으로 받아 적는 것을 막고, 의식적으로 자신의 **시스템 2(이성)를 활성화**하여 AI의 산출물을 **비평, 수정, 반박**하는 학습 활동과 **건설적 갈등의 문화** 조성이 필요합니다.

---

##  6. 추가 탐구 질문

* **집단적 함정 감지:** 만약 여러 학생이 유사한 AI의 직관적 산출물을 바탕으로 토론을 진행하고 서로를 **확증하는 잘못된 고리**에 빠진다면, 교사는 이 집단적 함정을 어떻게 감지하고 개입해야 할까?
* **시스템 2 작동 평가:** AI의 그럴듯한 시스템 1 산출물을 성공적으로 **비평하고 반박해낸 학생의 시스템 2 작동 과정**을 효과적으로 평가할 수 있는 방법은 무엇일까?

---

_**출처:** Rosenbacke, R., Rosenbacke, C., Rosenbacke, V., & McKee, M. (2025). Beyond hallucinations: The illusion of understanding in large language models. arXiv. https://arxiv.org/abs/2510.14665v1_

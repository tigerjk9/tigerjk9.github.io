---
title: "피상적인 산출에서 피상적인 학습으로: 교육에서 대형언어 모델의 위험성"
date: 2025-10-09 00:03:07 +0900
categories: [AI, 교육]
tags: [논문리뷰, LLM, AI윤리, 교육공학]
---

## 피상적인 산출에서 피상적인 학습으로: 교육에서 대형 언어 모델의 위험성

> 이 연구는 교육 분야에서 LLM의 활용과 관련된 위험성에 대한 실증적 증거들을 체계적으로 종합하고 분석합니다. 저자들은 LLM의 교육적 잠재력에 대한 낙관적인 담론을 넘어, 실제 연구들에서 보고된 기술적 및 교육학적 위험을 명확히 규명하고, "LLM의 피상적 결과물이 학생들의 피상적 학습으로 이어질 수 있다"는 중요한 경고를 던집니다.

![이미지](/assets/superficial-1.png)
![이미지](/assets/superficial-2.png)
![이미지](/assets/superficial-3.png)
<br>

### 1. 연구의 목적 🎯

이 연구의 주된 목적은 교육 분야에서 LLM의 활용과 관련된 **위험성(risks)**에 대한 실증적 증거들을 체계적으로 종합하고 분석하는 것입니다. 저자들은 LLM의 교육적 잠재력에 대한 낙관적인 담론을 넘어, 실제 연구들에서 보고된 기술적 및 교육학적 위험을 명확히 규명하고자 했습니다. 이를 위해 다음 네 가지 연구 질문을 설정했습니다.

* 어떤 LLM 교육 응용 프로그램이 가장 많이 연구되었는가?
* 그 영향은 주로 어떤 방법으로 측정되었는가?
* 이러한 응용 프로그램에서 어떤 위험이 발생하는가?
* 어떤 완화 전략이 제안되었는가?

<br>

### 2. 연구의 방법

본 연구는 PRISMA 가이드라인에 따른 **체계적 문헌 고찰(Systematic Review)** 방법론을 사용했습니다.
* **자료 검색:** 컴퓨터 과학 및 교육 분야의 주요 5개 데이터베이스(ACM DL, IEEE Xplore 등)에서 2015년부터 2025년까지 출판된 논문을 대상으로 키워드 검색을 수행했습니다.
* **선정 기준:** LLM 기반 도구를 교육에 적용하고, 그 과정에서 발생한 위험 또는 위험을 추론할 수 있는 결과를 보고한 **실증 연구(empirical studies)**만을 선정했습니다. 단순 인식 조사나 이론적 논문은 제외했습니다.
* **최종 분석 대상:** 초기 3,453개의 문헌 중, 최종적으로 2023년에서 2025년 사이에 출판된 70개의 논문을 선정하여 심층 분석을 진행했습니다.
* **분석 틀:** 선정된 연구들을 (1)운영 효율성, (2)개인화된 응용, (3)상호작용적 학습 도구라는 세 가지 응용 분야로 분류하고, 각 분야에서 보고된 위험들을 종합하여 새로운 분류 체계를 구축했습니다.

<br>

### 3. 주요 발견

이 연구는 LLM의 기술적 위험이 교육적 맥락에서 어떻게 학습자의 인지적, 행동적 위험으로 연쇄적으로 이어지는지를 명확히 보여주었습니다.

#### (1) 주요 응용 분야(RQ1)
LLM 연구는 주로 (1)운영 효율성(피드백 생성 등), (2)개인화된 응용(학생 특성에 따른 콘텐츠 생성 등), (3)상호작용적 학습 도구(학생 참여 및 인지적 영향 분석 등)의 세 영역에 집중되어 있었습니다.
![이미지](/assets/superficial-4.png)

> #### LLM의 주요 교육 응용 분야
>
> 1.  **운영 효율성 (Operational Effectiveness)**
>     이 분야는 LLM이 핵심적인 교육 관련 과업들을 얼마나 성공적으로 수행할 수 있는지를 평가하는 데 중점을 둡니다.
>     * **교육자를 위한 활용:** 교사들이 학생 과제에 대한 피드백을 생성하거나, 학생 데이터를 처리하는 등의 업무 자동화 연구가 포함됩니다.
>     * **학습자를 위한 활용:** 학생들이 특정 과목의 전문 지식에 대해 질문하고 답변을 얻는 경우를 분석합니다. (예: 전문 분야 시험 문제 풀이)
>
> 2.  **개인화된 응용 (Personalized Applications)**
>     이 분야는 LLM이 사용자의 인구통계학적 특성(성별, 인종 등)에 따라 어떻게 다르게 반응하는지, 즉 교육의 공정성 및 형평성 문제를 탐구합니다.
>     * **편향된 채점 및 평가:** 학생 프로필에 따라 LLM이 더 낮은 점수를 부여하는 등, 모델의 내재된 편향이 채점의 일관성을 해치는 사례를 분석합니다.
>     * **차별적인 콘텐츠 생성:** 사용자의 프로필에 따라 LLM이 생성하는 교육 콘텐츠나 진로 추천이 달라지는 현상을 탐구합니다.
>
> 3.  **상호작용적 학습 도구 (Interactive Learning Tools)**
>     이 분야는 학생들이 LLM 기반 도구와 직접 상호작용할 때 어떤 영향을 받는지에 초점을 맞춥니다.
>     * **학생 참여도 변화:** LLM 사용이 학생들의 주의력, 흥미, 비판적 검증 태도에 어떤 변화를 가져오는지 분석합니다.
>     * **인지적 영향:** LLM 사용이 학생들의 사고 과정에 미치는 영향을 탐구합니다. (예: 뇌 활동 감소)
>     * **학습 및 학업 성과:** LLM 사용이 최종 학습 결과와 학업 성취도에 미치는 영향을 평가합니다.

#### (2) 주요 위험성(RQ3)
* **모델 수준의 기술적 위험:** LLM 자체는 피상적인 이해, 편향, 제한된 견고성(일관성 부족), 의인화, 환각(Hallucinations), 개인정보 침해, 지식의 한계(오래된 정보) 등의 내재적 위험을 가집니다.
* **학습자 수준의 교육학적 위험:** 학습자가 LLM과 상호작용할 때, 기술적 위험은 교육학적 위험으로 증폭됩니다. 구체적으로 **뇌 활동 감소, 과잉 의존, 독립적인 학습 능력 저하, 학생 주도성 상실** 등의 인지적·행동적 결과로 이어집니다. 예를 들어, 학생들은 LLM의 권위적인 어조 때문에 비판적 검증 없이 답변을 수용하는 **'검증 표류(verification drift)'** 현상을 보였습니다.

> #### LLM의 주요 위험성
>
> ##### 1. 모델 수준의 기술적 위험 (Model-Level Risks)
> * **피상적인 이해 (Superficial Understanding):** 언어의 통계적 패턴만 학습할 뿐, 내용의 깊은 의미나 맥락을 진정으로 이해하지 못합니다.
> * **제한된 견고성 (Limited Robustness):** 동일한 프롬프트에도 일관되지 않은 답변을 생성하는 등 결과의 신뢰성이 떨어집니다.
> * **편향 증폭 (Amplification of Bias):** 훈련 데이터에 존재하는 사회적 편견(인종, 성별 등)을 증폭하여 결과물에 반영합니다.
> * **환각 (Hallucinations):** 사실과 다른 정보를 그럴듯하게 꾸며내거나 존재하지 않는 출처를 만들어냅니다.
> * **의인화 특성 (Anthropomorphic Characteristics):** 인간처럼 유창하고 자신감 있는 어조로 인해 사용자가 비판 없이 신뢰하게 만듭니다.
> * **개인정보 및 지식의 한계:** 민감 정보 유출 위험과 최신 정보를 반영하지 못하는 한계가 있습니다.
>
> ##### 2. 학습자 수준의 교육학적 위험 (Learner-Level Risks)
> * **인지적 및 메타인지적 위험:**
>     * **뇌 활동 감소:** LLM의 도움을 받을 때, 의미 통합이나 창의적 사고와 관련된 뇌 영역의 활성화가 현저히 감소합니다.
>     * **비판적 사고 및 메타인지 저하:** 스스로 정보를 평가하고 학습 전략을 계획, 점검하는 활동이 감소합니다. ("메타인지적 게으름")
>     * **기억력 감퇴:** 인지적 노력을 AI에 위임하면서 정보의 장기 기억 능력이 저하될 수 있습니다.
> * **행동적 위험:**
>     * **과잉 의존 (Over-reliance):** LLM 없이는 과제 수행에 어려움을 느끼고 스스로 문제 해결 노력을 포기하게 됩니다.
>     * **독립적인 학습 능력 약화:** 정보 검색, 비판적 분석 등 필수적인 학업 기술을 연습할 기회를 잃게 됩니다.
>     * **학생 주도성(Agency) 상실:** 학습의 주도권을 AI에게 넘겨주면서 능동적 주체로서의 역할이 약화됩니다.

#### (3) LLM-위험 적응 학습 모델(LLM-Risk Adapted Learning Model)
저자들은 이러한 위험의 연쇄적 과정을 설명하기 위해 '상호작용(Interaction) → 모니터링(Monitoring) → 결과(Outcome)'의 3단계로 구성된 개념 모델을 제안했습니다.

![이미지](/assets/superficial-5.png)
* **상호작용 단계:** 학습자가 LLM과 처음 만나는 단계로, AI의 기술적 위험이 비판적 사고 감소나 메타인지적 해이를 유발합니다.
* **모니터링 단계:** 학습자가 AI의 결과물을 처리하는 단계로, 편향된 정보를 무비판적으로 수용하면서 잘못된 신념이 내재화되고 뇌 활동 감소로 이어질 수 있습니다.
* **결과 단계:** 학습 성과가 나타나는 단계로, 누적된 위험들이 창의력 감소, 과잉 의존 등 부정적인 학습 결과로 나타납니다.

<br>

### 4. 결론 및 시사점

이 연구는 교육 분야에서 LLM의 위험을 실증적으로 종합한 최초의 체계적 문헌 고찰로서, **"LLM의 피상적 결과물(Superficial Outputs)이 학생들의 피상적 학습(Superficial Learning)으로 이어질 수 있다"**는 중요한 경고를 던집니다.

따라서 LLM을 교육에 책임감 있게 통합하기 위해서는 기술적 최적화를 넘어, 학습자의 자율성, 유능감, 관계성을 지원하는 **인간 중심적 설계**가 필수적입니다. 이는 교육자, 개발자, 학생, 정책 입안자 등 모든 이해관계자의 협력을 통해 이루어져야 합니다. 교육자들은 단순한 지식 전달을 넘어 비판적 사고와 같은 고차원적 역량을 강조하는 방향으로 교육 목표를 수정해야 하며, 학생들은 LLM을 비판적으로 검증하며 책임감 있게 사용하는 방법을 배워야 합니다. 결국 이 연구는 LLM이 혁신적 도구임은 분명하지만, 그 위험성을 명확히 인지하고 신중하게 접근해야만 진정한 교육적 가치를 실현할 수 있음을 강조합니다.

<br>

### 5. 리뷰어의 ADD(+) One: 생각 더하기

#### (1) 이 연구의 탁월한 점 (강점)
* **증거 기반의 체계성:** 의견이나 일화가 난무하는 LLM 교육 분야에서, 오직 '실증 연구'만을 대상으로 PRISMA 프로토콜에 따라 체계적으로 분석하여 결론의 신뢰도와 객관성을 크게 높였습니다.
* **학제 간 통합적 분석:** 컴퓨터 과학에서 식별된 기술적 위험(환각, 편향 등)이 교육학 및 심리학에서 관찰되는 교육학적 결과(메타인지 저하, 뇌 활동 감소 등)로 어떻게 이어지는지를 연결한 점이 매우 탁월합니다. 특히 **'LLM-위험 적응 학습 모델'**은 이 복잡한 연쇄 과정을 이해하는 데 매우 유용한 개념적 틀을 제공합니다.
* **포괄적인 범위:** 기술적 위험부터 인지적, 사회적(데이터 식민주의, 환경 문제 등) 위험까지, LLM이 교육에 미치는 부정적 영향을 매우 폭넓고 다각적으로 조망하여 독자에게 전체적인 그림을 제공합니다.

#### (2) 교육 현장을 위한 추가 제언
* **'AI 리스크 리터러시' 교육 필수화:** 이 연구는 LLM의 위험성이 기술적 문제를 넘어 학습자의 인지 및 행동에 직접적인 영향을 미침을 명확히 보여줍니다. 따라서 AI 활용법 교육을 넘어, **'AI 리스크 리터러시(AI Risk Literacy)'** 교육을 필수 교과 과정으로 도입해야 합니다. 학생들에게 AI의 환각, 편향, 피상적 이해와 같은 구체적인 위험 사례를 가르치고, 이를 비판적으로 식별하고 검증하는 훈련을 제공해야 합니다.
* **과정 중심의 평가 설계 전환:** LLM을 사용한 결과물(예: 에세이)은 문법적으로 완벽할 수 있지만, 학생의 비판적 사고나 창의성을 반영하지 못할 수 있습니다. 교육자들은 최종 결과물만 평가하는 방식에서 벗어나, 학생이 LLM과 상호작용하는 **'과정'**을 평가에 포함해야 합니다. 예를 들어, 어떤 프롬프트를 사용했는지, AI의 답변을 어떻게 수정하고 발전시켰는지, 여러 정보 소스를 교차 검증했는지 등을 보여주는 '학습 포트폴리오' 제출을 의무화할 수 있습니다.
* **인간 교사의 역할 재정의 및 강화:** 이 연구는 LLM이 피상적 피드백을 제공하고 교육적 가치와 상충되는 특성을 보일 수 있음을 지적합니다. 이는 AI가 대체할 수 없는 **'인간 교사'**의 역할—학생과의 공감대 형성, 깊이 있는 학습 동기 부여, 고차원적 사고를 자극하는 발문—이 더욱 중요해졌음을 의미합니다. 교육 정책은 교사들이 AI 도구의 '감독자'이자 '보완자'로서 기능할 수 있도록, 관련 연수와 지원을 강화해야 합니다.

<br>

### 6. 추가 탐구 질문

* 장기적으로 LLM을 활용한 학습 환경에 노출된 학생들의 뇌신경학적 발달_신경가소성(neuroplasticity)은 전통적인 학습자와 비교하여 어떻게 달라지는가?
* 'AI 리스크 리터러시' 교육을 받은 학생 집단은 그렇지 않은 집단에 비해 LLM 오용(예: 과잉 의존, 표절)을 더 효과적으로 방지하는가?
* LLM의 위험을 완화하도록 설계된 교육용 인터페이스(예: AI 답변의 신뢰도를 시각적으로 표시, 비판적 질문 자동 생성)는 학생들의 피상적 학습을 실제로 줄일 수 있는가?
* 서로 다른 문화권의 학생들이 동일한 LLM을 사용할 때, 모델의 내재된 문화적 편향(예: Anglocentric bias)이 학습 경험과 결과에 미치는 영향의 차이는 무엇인가?

---

_**출처:**_
_- Delikoura, I., Fung, Y. R. , & Hui, P. (2025). From Superficial Outputs to Superficial Learning: Risks of Large Language Models in Education. arXiv. https://arxiv.org/abs/2509.21972_

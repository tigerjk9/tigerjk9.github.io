---
title: "LLMs Can Get Brain Rot! LLM의 인지 저하 현상"
date: 2025-10-22 01:23:00 +0900
categories: [AI]
tags: [논문리뷰, BrainRot]
---

## LLMs Can Get "Brain Rot"! LLM의 인지 저하 현상

> 본 논문은 인간 사회에서 온라인 정크 데이터 소비가 인지 저하를 유발하는 현상인 브레인 로트(Brain Rot)가 대규모 언어 모델(LLM)에도 동일하게 발생할 수 있다는 가설을 제기하고 실험적으로 검증합니다. 교육적 관점에서 AI를 학습 도구로 사용하는 학생과 교사에게 데이터의 '질'이 AI의 '사고 능력'에 미치는 영향을 명확히 보여주는 매우 중요한 연구입니다.

<br>

### 1. 연구의 목적

이 연구의 핵심 목적은 'LLM 브레인 로트 가설(LLM Brain Rot Hypothesis)'을 제안하고 검증하는 것입니다. 즉, 저품질의 '정크(junk)' 웹 텍스트에 지속적으로 노출되는 것이 LLM의 영구적인 인지 능력 저하를 유발하는지 과학적으로 밝히는 데 있습니다.

![이미지](/assets/brain-rot-1.png)

<br>

### 2. 연구의 방법

연구진은 가설을 검증하기 위해 다음과 같은 정교한 통제 실험(Controlled Experiment)을 설계했습니다.

![이미지](/assets/brain-rot-2.png)

1.  **데이터셋 구축:** 실제 트위터(X) 데이터를 기반으로 '정크 데이터셋'과 '통제(고품질) 데이터셋'을 구축했습니다.
2.  **정크 데이터의 조작적 정의:** 정크 데이터는 두 가지 기준(M1, M2)으로 정의되었습니다.
    * **M1 (참여도 기준):** 내용은 짧지만 '좋아요', '리트윗' 등 사용자의 참여도가 매우 높은 게시물
    * **M2 (의미 품질 기준):** 내용이 선정적이거나 피상적이고, 클릭을 유도하는 스타일의 게시물
3.  **실험 과정:** 4개의 서로 다른 LLM을 정크 데이터 그룹과 통제 데이터 그룹으로 나누어 각각 지속적인 사전 훈련(continual pre-training)을 수행했습니다. 그 후, 추론 능력, 장문 이해력, 안전성, 성격 특성 변화 등 다양한 벤치마크를 통해 두 그룹의 인지 능력 변화를 비교 측정했습니다.

<br>

### 3. 주요 발견

실험 결과, LLM 브레인 로트 가설을 뒷받침하는 강력한 증거들이 발견되었습니다.

* **전반적인 인지 능력 저하:** 정크 데이터로 훈련된 LLM은 통제 그룹에 비해 추론, 장문 이해, 안전성 측면에서 심각하고 통계적으로 유의미한 성능 저하를 보였습니다.
* **어두운 성격 특성의 발현:** 특히 참여도(M1) 기반의 정크 데이터는 LLM의 사이코패스(Psychopathy), 나르시시즘(Narcissism)과 같은 사회적으로 바람직하지 않은 어두운 성격 특성을 증폭시키는 것으로 나타났습니다.
* **핵심 실패 원인 '사고 건너뛰기(Thought-skipping)':** 성능이 저하된 핵심적인 이유로, LLM이 문제 해결을 위한 논리적 추론 과정을 생략하거나 건너뛰는 `사고 건너뛰기` 현상이 지목되었습니다.
* **영구적인 손상 가능성:** '브레인 로트'가 발생한 LLM에 고품질 데이터를 추가로 학습시키거나 명령어 튜닝(Instruction Tuning)을 진행했을 때 성능이 일부 회복되었지만, 초기 상태로 완전히 복구되지는 않았습니다. 이는 저품질 데이터가 LLM에 영구적인 손상을 남길 수 있음을 시사합니다.

<br>

### 4. 결론 및 시사점

본 연구는 데이터의 품질이 LLM의 성능 저하를 유발하는 **핵심적인 원인(causal driver)**임을 명확히 보여줍니다. 이는 LLM을 위한 데이터 큐레이션이 단순한 성능 향상 문제를 넘어, AI의 **안전성(safety)**을 확보하기 위한 필수적인 과제임을 의미합니다. 저자들은 우리가 인간의 건강을 염려하듯, 지속적으로 운영되는 LLM에 대한 **주기적인 인지 건강 검진(cognitive health checks)**이 필요하다고 강력하게 제언합니다.

<br>

### 5. 리뷰어의 ADD(+) One: 생각 더하기

#### (1) 이 연구의 탁월한 점 (강점)
* **직관적이고 강력한 가설:** '브레인 로트'라는 현대 사회의 현상을 LLM에 접목하여, AI 데이터 품질의 중요성을 누구나 쉽게 이해할 수 있도록 개념화했습니다.
* **정교한 실험 설계:** 참여도와 의미 품질이라는 두 가지 다른 렌즈로 정크 데이터를 정의하고 통제 실험을 통해 인과관계를 밝힘으로써 연구의 신뢰도를 크게 높였습니다.
* **구체적인 메커니즘 규명:** AI의 성능 저하를 단순히 '성능 하락'으로만 본 것이 아니라, `사고 건너뛰기`라는 구체적인 실패 메커니즘을 밝혀내어 문제 해결을 위한 실마리를 제공했습니다.

#### (2) 교육 현장을 위한 추가 제언
* **디지털 영양 교육의 확장:** 학생들에게 좋은 정보를 소비하는 것을 넘어, AI에게 건강한 데이터(질문)를 제공하고 AI의 답변 품질을 비판적으로 평가하는 `AI 조련사(AI Trainer)`로서의 역량을 가르쳐야 합니다. "나쁜 것을 먹이면, 나쁘게 생각한다"는 원리를 AI에도 적용해야 합니다.
* **교육용 AI의 '학습 데이터' 투명성 요구:** 학교나 교육 기관에서 도입하는 AI 서비스에 대해 어떤 종류의 데이터로 학습되었는지 투명하게 공개하도록 요구해야 합니다. 정크 웹 데이터로만 학습된 AI는 학생들의 비판적 사고 능력을 저해하는 인지적 유해물이 될 수 있습니다.
* **사고 과정 평가의 중요성:** AI가 내놓은 정답만 볼 것이 아니라, 그 답을 도출하기까지의 사고 과정(Chain of Thought)을 보여달라고 요구하고, 그 과정이 논리적인지, 건너뛴 부분은 없는지 함께 평가하는 훈련이 교육 과정에 포함되어야 합니다.

<br>

### 6. 추가 탐구 질문

* 인간의 뇌가 휴식과 수면을 통해 정보를 정리하듯, LLM에게도 '브레인 로트'를 회복시키기 위한 특정 '휴지기'나 '데이터 소화' 과정(예: 파라미터 재정렬, 중요도 낮은 데이터 망각)이 효과적일 수 있을까요?
* 특정 유형의 '인지적 훈련(Cognitive Training)' 데이터셋(예: 논리 퍼즐, 복잡한 추론 문제)을 만들어 '브레인 로트'에 걸린 LLM을 효과적으로 재활시킬 수 있을까요?
* `사고 건너뛰기` 현상은 LLM의 창의적 문제 해결 능력에는 어떤 영향을 미칠까요? 때로는 논리적 도약이 창의성으로 이어지기도 하는데, 이 현상이 항상 부정적이기만 할까요?

---

_**출처:**_
* _Xing, S., Hong, J., Wang, Y., Chen, R., Zhang, Z., Grama, A., Tu, Z., & Wang, Z. (2025). LLMS CAN GET "BRAIN ROT"!. arXiv preprint._
